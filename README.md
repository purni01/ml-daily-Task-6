# ml-daily-Task-6

What I Did

1. **Dataset Used:** Iris dataset from `sklearn.datasets`.
2. **Preprocessing:** Normalized all features using `StandardScaler`.
3. **Model:** Used `KNeighborsClassifier` from `sklearn.neighbors`.
4. **K Tuning:** Tested values of `K` from 1 to 10 and compared accuracies.
5. **Evaluation:** Evaluated performance using `accuracy_score` and `confusion_matrix`.
6. **Visualization:** Plotted decision boundaries using the first two features.

 Libraries Used

- `pandas`
- `numpy`
- `matplotlib`
- `scikit-learn`

 Key Learnings

- KNN is an instance-based learning algorithm that relies on distance metrics.
- Normalization is crucial since KNN uses Euclidean distances.
- The choice of `K` impacts bias vs. variance.
- Confusion matrix helps analyze multi-class performance.
- Decision boundaries visually explain model behavior.


